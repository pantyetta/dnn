{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの構造\n",
    "input_size = 3    # 入力層のニューロン数\n",
    "hidden_size_1 = 4   # 隠れ層のニューロン数\n",
    "output_size = 2   # 出力層のニューロン数\n",
    "\n",
    "# 学習率\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
      "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
      "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351]])\n",
      "array([[0., 0., 0., 0.]])\n",
      "array([[ 0.76103773,  0.12167502],\n",
      "       [ 0.44386323,  0.33367433],\n",
      "       [ 1.49407907, -0.20515826],\n",
      "       [ 0.3130677 , -0.85409574]])\n",
      "array([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 重みの初期化\n",
    "np.random.seed(0) # 再現性のためのシード値設定\n",
    "W1 = np.random.randn(input_size, hidden_size_1)  # 入力層から隠れ層1への重み\n",
    "b1 = np.zeros((1, hidden_size_1))                # 隠れ層1のバイアス\n",
    "W2 = np.random.randn(hidden_size_1, output_size) # 隠れ層1から出力層への重み\n",
    "b2 = np.zeros((1, output_size))                # 出力層のバイアス\n",
    "\n",
    "pprint.pprint(W1)\n",
    "pprint.pprint(b1)\n",
    "pprint.pprint(W2)\n",
    "pprint.pprint(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# シグモイド関数の導関数\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# relu関数\n",
    "def relu(x):\n",
    "    return x * (0 < x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "    # 隠れ層への入力\n",
    "    test = np.dot(X, W1)\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    # 出力層への入力\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    return a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, a1, a2):\n",
    "    global W1, b1, W2, b2\n",
    "\n",
    "    # 出力層の誤差\n",
    "    output_error = y - a2\n",
    "    output_delta = output_error * sigmoid_derivative(a2)\n",
    "\n",
    "    # 隠れ層の誤差\n",
    "    hidden_error = np.dot(output_delta, W2.T)\n",
    "    hidden_delta = hidden_error * sigmoid_derivative(a1)\n",
    "\n",
    "    # 重みとバイアスの更新\n",
    "    W2 += learning_rate * np.dot(a1.T, output_delta)\n",
    "    b2 += learning_rate * np.sum(output_delta, axis=0, keepdims=True)\n",
    "    W1 += learning_rate * np.dot(X.T, hidden_delta)\n",
    "    b1 += learning_rate * np.sum(hidden_delta, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, iterations):\n",
    "    for i in range(iterations):\n",
    "        # フォワードプロパゲーション\n",
    "        a1, a2 = forward_propagation(X)\n",
    "        \n",
    "        # バックプロパゲーション\n",
    "        backward_propagation(X, y, a1, a2)\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            loss = np.mean(np.square(y - a2))\n",
    "            print(f'Iteration {i+1}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Loss: 0.24570491133209074\n",
      "Iteration 2000, Loss: 0.2418688752346055\n",
      "Iteration 3000, Loss: 0.23756111038779104\n",
      "Iteration 4000, Loss: 0.23246377297320198\n",
      "Iteration 5000, Loss: 0.22634825476644677\n",
      "Iteration 6000, Loss: 0.2191330790829629\n",
      "Iteration 7000, Loss: 0.21094254239219234\n",
      "Iteration 8000, Loss: 0.20214036615841774\n",
      "Iteration 9000, Loss: 0.19337892626082553\n",
      "Iteration 10000, Loss: 0.18534242192228162\n"
     ]
    }
   ],
   "source": [
    "# トレーニングデータの例\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0, 1],\n",
    "              [1, 0],\n",
    "              [1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# 学習を実行\n",
    "train(X, y, 10000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
