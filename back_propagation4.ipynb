{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークの構造\n",
    "input_size = 3    # 入力層のニューロン数\n",
    "hidden_size_1 = 4   # 隠れ層のニューロン数\n",
    "hidden_size_2 = 4   # 隠れ層のニューロン数\n",
    "output_size = 2   # 出力層のニューロン数\n",
    "\n",
    "# 学習率\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 1.76405235,  0.40015721,  0.97873798,  2.2408932 ],\n",
      "       [ 1.86755799, -0.97727788,  0.95008842, -0.15135721],\n",
      "       [-0.10321885,  0.4105985 ,  0.14404357,  1.45427351]])\n",
      "array([[0., 0., 0., 0.]])\n",
      "array([[ 0.76103773,  0.12167502,  0.44386323,  0.33367433],\n",
      "       [ 1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
      "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502],\n",
      "       [ 2.26975462, -1.45436567,  0.04575852, -0.18718385]])\n",
      "array([[0., 0., 0., 0.]])\n",
      "array([[ 1.53277921,  1.46935877],\n",
      "       [ 0.15494743,  0.37816252],\n",
      "       [-0.88778575, -1.98079647],\n",
      "       [-0.34791215,  0.15634897]])\n",
      "array([[0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 重みの初期化\n",
    "np.random.seed(0) # 再現性のためのシード値設定\n",
    "W1 = np.random.randn(input_size, hidden_size_1)  # 入力層から隠れ層1への重み\n",
    "b1 = np.zeros((1, hidden_size_1))                # 隠れ層1のバイアス\n",
    "W2 = np.random.randn(hidden_size_1, hidden_size_2) # 隠れ層1から隠れ層2への重み\n",
    "b2 = np.zeros((1, hidden_size_2))                # 隠れ層2のバイアス\n",
    "W3 = np.random.randn(hidden_size_2, output_size) # 隠れ層2から出力層への重み\n",
    "b3 = np.zeros((1, output_size))                # 出力層のバイアス\n",
    "\n",
    "pprint.pprint(W1)\n",
    "pprint.pprint(b1)\n",
    "pprint.pprint(W2)\n",
    "pprint.pprint(b2)\n",
    "pprint.pprint(W3)\n",
    "pprint.pprint(b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シグモイド関数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# シグモイド関数の導関数\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# relu関数\n",
    "def relu(x):\n",
    "    return x * (0 < x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X):\n",
    "    # 隠れ層1への入力\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    # 隠れ層2への入力\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # 出力層への入力\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    return a1, a2, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, y, a1, a2, a3):\n",
    "    global W1, b1, W2, b2, W3, b3\n",
    "\n",
    "    # 出力層の誤差\n",
    "    output_error = y - a3\n",
    "    output_delta = output_error * sigmoid_derivative(a3)\n",
    "\n",
    "    # 隠れ層の誤差\n",
    "    hidden_2_error = np.dot(output_delta, W3.T)\n",
    "    hidden_2_delta = hidden_2_error * sigmoid_derivative(a2)\n",
    "\n",
    "    # 隠れ層の誤差\n",
    "    hidden_1_error = np.dot(hidden_2_delta, W2.T)\n",
    "    hidden_1_delta = hidden_1_error * sigmoid_derivative(a1)\n",
    "\n",
    "    # 重みとバイアスの更新\n",
    "    W3 += learning_rate * np.dot(a1.T, output_delta)\n",
    "    b3 += learning_rate * np.sum(output_delta, axis=0, keepdims=True)\n",
    "    W2 += learning_rate * np.dot(a1.T, hidden_2_delta)\n",
    "    b2 += learning_rate * np.sum(hidden_2_delta, axis=0, keepdims=True)\n",
    "    W1 += learning_rate * np.dot(X.T, hidden_1_delta)\n",
    "    b1 += learning_rate * np.sum(hidden_1_delta, axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, iterations):\n",
    "    for i in range(iterations):\n",
    "        # フォワードプロパゲーション\n",
    "        a1, a2, a3 = forward_propagation(X)\n",
    "        \n",
    "        # バックプロパゲーション\n",
    "        backward_propagation(X, y, a1, a2, a3)\n",
    "        \n",
    "        if (i+1) % 1000 == 0:\n",
    "            loss = np.mean(np.square(y - a3))\n",
    "            print(f'Iteration {i+1}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1000, Loss: 1.8062941861995037e-05\n"
     ]
    }
   ],
   "source": [
    "# トレーニングデータの例\n",
    "X = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [1, 1, 1]])\n",
    "\n",
    "y = np.array([[0, 1],\n",
    "              [1, 0],\n",
    "              [1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# 学習を実行\n",
    "train(X, y, 10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
